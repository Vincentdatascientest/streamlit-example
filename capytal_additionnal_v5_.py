# -*- coding: utf-8 -*-
"""CaPytal Additionnal_V5 .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/gist/Vincentdatascientest/2d056f2c48fb8e5c9d1a59b55c399ed3/capytal-additionnal_v5.ipynb

#**PROJET CaPytal**
défintion des variables: [ICI](https://archive.ics.uci.edu/ml/datasets/bank+marketing)

# Préambule

### Import & chargement
"""

# Commented out IPython magic to ensure Python compatibility.
#Import des modules

# Modules complémentaires

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from scipy.stats import chi2_contingency
import statsmodels.api 
from scipy.stats import pearsonr
# %matplotlib inline


# PREPORCESSING
from sklearn import preprocessing
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split


#sklearn
from sklearn import model_selection
from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import plot_confusion_matrix
from sklearn.model_selection import RandomizedSearchCV
from sklearn import metrics
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix,r2_score
from sklearn.ensemble import BaggingClassifier
from sklearn import decomposition, datasets
from sklearn.pipeline import Pipeline
from sklearn.model_selection import GridSearchCV

#KNN
from sklearn import neighbors
from sklearn.neighbors import KNeighborsClassifier

#SVM
from sklearn import svm
from sklearn import model_selection
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.svm import SVC 


#linear
from sklearn import linear_model

#Random Forest
from sklearn import ensemble
from sklearn.ensemble import RandomForestClassifier

#Decison Tree
from sklearn.tree import DecisionTreeClassifier
from sklearn.tree import plot_tree
from sklearn import tree

#Xgboost
import xgboost as xgb
from xgboost import XGBClassifier


#LogisticRegression
from sklearn.linear_model import LogisticRegression


# Autres
import os
import warnings
from imblearn.over_sampling import SMOTE
warnings.filterwarnings('ignore')
import tensorflow as tf
from tensorflow import keras 
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam 
from sklearn.ensemble import AdaBoostClassifier
from sklearn.metrics import f1_score
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, roc_curve, recall_score
from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold, RandomizedSearchCV, cross_val_score
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis
from sklearn.ensemble import RandomForestClassifier,VotingClassifier
from imblearn.under_sampling import RandomUnderSampler
from imblearn.over_sampling import RandomOverSampler, SMOTE
from collections import Counter
from pprint import pprint
from scipy import stats

url = 'https://drive.google.com/file/d/1WnBL1zEQo1KVEinJBN6ZfyeW4U4d7Yk3/view?usp=sharing'
path = 'https://drive.google.com/uc?export=download&id='+url.split('/')[-2]

df = pd.read_csv(path, sep = ';')
df = df.rename(columns={'y': 'deposit'})

colors = ['#0F7CBF','#0A3B59','#91BDD9','#C4E1F2','#0F8DBF','#C3CEDA','#738FA7','#0C4160','#071330','#071330','#D83B23']

df.head()

"""## Le Dataframe"""

df.head()

df.info()

"""Le DataFrame ne comporte pas de valeurs manquantes et les données semblent être sous le bon format."""

df.describe()

"""# **I - DISTRIBUTION & CORRELATION**

## A - Distribution des variables

###1 -  Profil socio-démographique
"""

#@title
plt.figure(figsize=(15,15))

plt.subplot(221)
plt.hist(df['age'], bins=[10,20,30,40,50,60,70,80,90], rwidth=0.8, density = True,color = '#0F7CBF')
plt.title('Distribution de la variable âge')

plt.subplot(222)
plt.pie(df['job'].value_counts(), 
        labels=['Manag', 'Blue-Collar', 'Technicians', 'Admin', 'Services', 'Retired', 'Self-Employed', 'Student', 'Unemployed','Entrepreneur', 'Housemaid', 'Unknown'],
       autopct= lambda x : str(round(x,1)) + '%', colors=colors);
plt.title('Distribution de la variable job')

plt.subplot(223)
plt.pie(df['marital'].value_counts(),
       labels=['married','single','divorced', 'unknown'],
       autopct= lambda x : str(round(x,1)) + '%', colors=colors);
plt.title('Distribution de la variable statut marital')

def educ(cell):
    if  'university.degree' in cell:
        return 'tertiary'
    elif 'high.school' in cell:
        return 'secondary'
    elif'basic.9y' in cell:
        return 'primary'
    elif'professional.course' in cell:
        return 'secondary'
    elif'basic.4y' in cell:
        return 'primary'
    elif'basic.6y' in cell:
        return 'primary'
    elif'illiterate' in cell:
        return 'primary'
    elif 'unknow' in cell :
        return 'unknown'
  
df['educ'] = df['education'].apply(educ)

plt.subplot(224)
plt.pie(df['educ'].value_counts(),
       labels=['secondary','tertiary','primary', 'unknown'], 
        autopct= lambda x : str(round(x,1)) + '%',
        colors=colors)
plt.title('Distribution de la variable éducation');

"""###2 -  Profil financier"""

#@title
plt.figure(figsize=(15,15))

plt.subplot(221)
plt.pie(df['default'].value_counts(), 
        labels=['no', 'yes', 'unknown'],
       autopct= lambda x : str(round(x,1)) + '%',colors=colors);
plt.title('Répartition Prospects déficitaires')

plt.subplot(222)
plt.pie(df['housing'].value_counts(), 
        labels=['no', 'yes', 'unknown'],
       autopct= lambda x : str(round(x,1)) + '%',colors=colors);
plt.title('Répartition Prospects ayant un emprunt immobilier')

plt.subplot(223)
plt.pie(df['loan'].value_counts(), 
        labels=['no', 'yes', 'unknown'],
       autopct= lambda x : str(round(x,1)) + '%',colors=colors);
plt.title('Répartition Prospects ayant un emprunt personnel');

"""###3 -  Campagnes marketing"""

plt.figure(figsize=(5,5))

plt.pie(df['deposit'].value_counts(),
        labels=['no', 'yes'],
       autopct= lambda x : str(round(x,1)) + '%',colors=colors);
plt.title('Répartition prospects ayant effectué un depot à terme');

#@title
# standardisation des mois pour analyser la distribution


def monthToNum(shortMonth):
    return {
            'jan': 1,
            'feb': 2,
            'mar': 3,
            'apr': 4,
            'may': 5,
            'jun': 6,
            'jul': 7,
            'aug': 8,
            'sep': 9, 
            'oct': 10,
            'nov': 11,
            'dec': 12
    }[shortMonth]

df['month_modif'] = df['month'].apply(monthToNum)
df['month_modif']= df['month_modif'].sort_values()


g = sns.FacetGrid(df, col='deposit',height=7)
g.map(plt.hist, 'campaign',color='#91BDD9',edgecolor='black', linewidth=1.2);

g = sns.FacetGrid(df, col='deposit',height=7)
g.map(plt.hist,'month',color='#0F7CBF',edgecolor='black',linewidth=1.2, rwidth = 0.8);
plt.xticks (range(0,11),df['month'].unique());

g = sns.FacetGrid(df, col='deposit',height=7)
g.map(plt.hist, 'day_of_week',color='#91BDD9',edgecolor='black', linewidth=1.2, rwidth = 0.8, bins=[0,1,2,3,4,5,6,7]);
plt.xticks (range(0,7), df['day_of_week'].unique());

g = sns.FacetGrid(df, col='deposit',height=7)
g.map(plt.hist, 'contact',color='#0F7CBF',edgecolor='black', linewidth=1.2);




# sns.displot(df, x="month_modif", binwidth=1,color='#0F7CBF',hue='deposit'); 
# sns.displot(df, x="campaign", binwidth=10,color='#0F7CBF',hue='deposit');
# sns.displot(df, x="day", binwidth=5,kde=True,color='#0F7CBF',hue='deposit');
# sns.displot(df, x="contact", binwidth=5,color='#0F7CBF',hue='deposit')

#@title
sns.set_style("darkgrid")
g = sns.FacetGrid(df, col='deposit',height=8)
g.map(plt.hist, 'month',color='#91BDD9',bins=10,linewidth=1.5);

"""C'est très majoritairement la campagne 1 qui convertie
Pas de réelle saisonnalité sur les conversions.
Comme nous ne connaissons pas l'année, il est impossible de visualiser une saisonnalité par jour nommé (Dommage !)

###4 - Caractéristiques du contexte social et économique
"""

sns.boxplot(x='nr.employed', palette = colors, data=df)
print(df['nr.employed'].describe())

"""La médiane se rapproche plus de la valeur maximale. Il n'y a pas des valeurs aberrantes mais les données ne sont pas normales.



"""

sns.boxplot(x="cons.price.idx", palette = colors, data=df)
print(df['cons.price.idx'].describe())

"""Distribution des données semble plutôt normale, mais la différence entre la mediane et la moyenne dans ce contexte n'est pas négligeable. """

sns.boxplot(x="cons.conf.idx", palette = colors, data=df)
print(df['cons.conf.idx'].describe())

"""Valeur aberrante retrouvé. La distribution semble assez symétrique, mais la différence entre la mediane et la moyenne dans ce contexte n'est pas négligeable."""

sns.boxplot(x="euribor3m", palette = colors, data=df)
print(df['euribor3m'].describe())

"""La moyenne et la médiane sont assez éloignées, les valeurs ne sont pas normalement distribuées et la médiane est la meilleure représentation."""

sns.boxplot(x="emp.var.rate", palette = colors, data=df)
print(df['emp.var.rate'].describe())

"""La médiane se rapproche plus de la valeur maximale. Il n'y a pas des valeurs aberrantes mais les données ne sont pas normales.

## B - Variables explicatives vs cible

###1 -  Variables socio-démographiques

**AGE / DEPOSIT**
"""

#@title
df['age_cut'] = pd.cut(x=df['age'], bins = [10,20,30,40,50,60,70,80,90], labels = ['10+','20+','30+','40+','50+','60+','70+','80+'])

sns.catplot(x= 'age_cut', hue="deposit", kind="count", data=df, height=7, legend = False,color = '#91BDD9',edgecolor='black', linewidth=1)
plt.legend(title='Le client a-t-il souscrit a un depot a terme?', loc='upper right', labels=['Non', 'Oui'], bbox_to_anchor= (1.8,1))
plt.xlabel("tranches d'age");

"""L'age median du client ayant effectué un deposit est d'environ 37 ans. Les trentenaires sont les plus nombreux à avoir effectué un dépot à terme mais en proportion ce sont les 50 ans et + qui sont plus sousceptible à souscrire versus ne pas souscrire."""

#@title
plt.figure(figsize=(5,10))

sns.boxplot(x= 'deposit', y='age',data=df,color = '#91BDD9')
plt.legend(title='Le client a-t-il souscrit a un depot a terme?', loc='upper right', labels=['Oui', 'Non'], bbox_to_anchor= (1.8,1));

"""**EDUCATION / DEPOSIT**"""

#@title
sns.catplot(x= 'educ', hue="deposit", kind="count", data=df, height=7, legend = False,color = '#91BDD9',edgecolor='black', linewidth=1)
plt.legend(title='Le client a-t-il souscrit a un depot a terme?', loc='upper right', labels=['Non', 'Oui'], bbox_to_anchor= (1.8,1));

"""Le nombre de clients ayant souscrit un dépôt à terme est à peu près équivalente entre les niveaux d'éducation (sauf 'unknown'), cependant le taux de 'Oui' est plus important pour les personnes ayant un niveau d'éducation 'tertiary'.

**JOB / DEPOSIT**
"""

#@title
def term_job(cell):
    if  'admin.' in cell:
        return 'worker'
    elif 'technician' in cell:
        return 'worker'
    elif'services' in cell:
        return 'worker'
    elif'management' in cell:
        return 'worker'
    elif'blue-collar' in cell:
        return 'worker'
    elif'self-employed' in cell:
        return 'worker'
    elif'retired' in cell:
        return 'worker'
    elif'unemployed' in cell:
        return 'not worker'
    elif'housemaid' in cell:
        return 'not worker'
    elif'student' in cell:
        return 'not worker'
    elif'unknown' in cell:
        return 'unknown'
    return

df['jobcat'] = df['job'].apply(term_job);

sns.catplot(x="jobcat", hue="deposit", kind="count", data=df, height=7, legend = False,color = '#91BDD9',edgecolor='black', linewidth=1)
plt.legend(title='Le client a-t-il souscrit a un depot a terme?', loc='upper right', labels=['Non', 'Oui'], bbox_to_anchor= (1.8,1));

"""Nous pouvons observer que le groupe des clients ayant un emploi est beaucoup plus important que pour les groupes sans-emploi et inconnu. Possible corrélation à verifier.

**MARITAL / DEPOSIT**
"""

sns.catplot(x= 'marital', hue="deposit", kind="count", data=df, height=7, legend = False,color = '#91BDD9',edgecolor='black', linewidth=1)
plt.legend(title='Le client a-t-il souscrit a un depot a terme?', loc='upper right', labels=['Non', 'Oui'], bbox_to_anchor= (1.8,1))
plt.title("Souscription au dépôt à terme en fonction du statut marital");

"""Les clients mariés sont les plus nombreux à avoir souscrit à un dépôt à terme, cependant il semble y avoir une proportionalité de souscription/non-souscription dans les différents groupes.

### 2 - Variables financiéres

**LOAN / DEPOSIT**
"""

#@title
sns.catplot(x="loan", hue="deposit", kind="count", data=df, height=7, legend = False, edgecolor='black', color = '#0F7CBF')
plt.xlabel('Le client a-t-il un pret personnel?')
plt.ylabel('Nombre des clients')
plt.legend(title='Le client a-t-il souscrit a un depot a terme?', loc='upper right', labels=['Non', 'Oui'], bbox_to_anchor= (1.8,1));

"""Nous observons que le groupe des clients n'ayant pas déjà un prêt bancaire compte plus de souscripteurs que les autres groupes. Possible corrélation à verifier.

Les variables loan et deposit sont inexistantes.

**HOUSING / DEPOSIT**
"""

#@title
figsize = (50,50)
sns.catplot(x="housing", hue="deposit", kind="count", data=df,color = '#0F7CBF', height=7,edgecolor='black', legend = False)
plt.xlabel('Le client a-t-il un pret immobilier?')
plt.ylabel('Nombre des clients')
plt.legend(title='Le client a-t-il souscrit a un depot a terme?', loc='upper right', labels=['Non', 'Oui'], bbox_to_anchor= (1.8,1));

"""Les groupes et le fait de souscrire ou non à un dépôt semble proportionnelles, même si les clients du groupe ayant un prêt immobillier ont été plus nombreux à souscrire à un dépot. Corrélation à vérifier.

**DEFAULT / DEPOSIT**
"""

#@title
figsize = (20,20)
sns.catplot(x="default", hue="deposit", kind="count", data=df, color = '#0F7CBF', height=7, edgecolor='black', legend = False)
plt.xlabel('Le client a-t-il un crédit en impayé ?')
plt.ylabel('Nombre des clients')
plt.legend(title='Le client a-t-il souscrit a un depot a terme?', loc='upper right', labels=['Non', 'Oui'], bbox_to_anchor= (1.6,1));

"""Aucun client ayant déjà un crédit non payé n'a souscrit à un dépôt. Parmis les groupes 'no' et 'unknown' le taux de souscripteurs et non souscripteurs semble proportionnel.

###3 - Variables de campagne

**CONTACT / DEPOSIT**
"""

figsize = (20,20)
sns.catplot(x="contact", hue="deposit", kind="count", data=df, color = '#0F7CBF', height=7, edgecolor='black', legend = False)
plt.xlabel('La méthode de contact')
plt.ylabel('Nombre des clients')
plt.legend(title='Le client a-t-il souscrit a un depot a terme?', loc='upper right', labels=['Non', 'Oui'], bbox_to_anchor= (1.8,1));

"""Les clients contactés par téléphone mobile sont les plus nombreux à avoir souscrit à un dépôt. Nous observons cependant une proportionnalité de souscripteurs/non-souscripteurs parmis les deux groupes.

**MONTH / DEPOSIT**
"""

sns.catplot(x="month", hue="deposit", kind="count", data=df, color = '#0F7CBF', height=7, edgecolor='black', legend = False)
plt.xlabel('Le dernier mois de contact')
plt.ylabel('Nombre des clients')
plt.legend(title='Le client a-t-il souscrit a un depot a terme?', loc='upper right', labels=['Non', 'Oui'], bbox_to_anchor= (1.8,1));

"""Les clients dont le dernier contact a eu lieu en mai sont largement plus nombreux à avoir souscrit à un dépôt à terme. Corrélation possible à tester.

**DAY OF WEEK / DEPOSIT**
"""

sns.catplot(x="day_of_week", hue="deposit", kind="count", data=df, color = '#0F7CBF', height=7, edgecolor='black', legend = False)
plt.xlabel('Le dernier jour de contact')
plt.ylabel('Nombre des clients')
plt.legend(title='Le client a-t-il souscrit a un depot a terme?', loc='upper right', labels=['Non', 'Oui'], bbox_to_anchor= (1.8,1));

"""Le nombre de clients ayant souscrit ou non à un prêt semble cohérent parmi les derniers jours où le client a été contacté, donc pas de corrélation visible.

**POUTCOME / DEPOSIT**
"""

#@title
figsize = (20,20)
sns.catplot(x="poutcome", hue="deposit", kind="count", data=df, color = '#0F7CBF', height=7, edgecolor='black', legend = False)
plt.xlabel("L'effet de la dernière campagne sur le client?")
plt.ylabel('Nombre des clients')
plt.legend(title='Le client a-t-il souscrit a un depot a terme', loc='upper right', labels=['Non', 'Oui'], bbox_to_anchor= (1.6,1));

"""Les clients n'ayant pas étés ciblés par la dernière campagne publicitaire de la banque constituent la majorité de dépôts à terme, contrairement à ceux qui ont déjà été ciblé par la campagne. Les clients pour qui cette dernière campagne a été consideré comme succès sont les moins nombreux à souscrire. Possible corrélation à noter.

**DAYS PASSED FROM PREVIOUS CAMPAIGN / DEPOSIT**
"""

#@title
sns.violinplot(x="deposit", y = 'pdays', palette = colors, data=df)

"""La distribution et la corrélation sont difficiles à observer pour cette variable.

**DURATION / DEPOSIT**
"""

#@title
plt.figure(figsize=(3,6))
sns.set(style="darkgrid")
sns.boxplot(x='deposit', y='duration', data=df[df['duration']<2000],color='#0F7CBF');

"""La durée de l'appel semble avoir un impact sur la souscription ou non au contrat de dépôt à terme, la médiane et les quartiles de la variable 'duration' sont sensiblement supérieurs pour les 'yes'. Corrélation à tester.

**PREVIOUS / DEPOSIT**
"""

#@title
sns.histplot(data = df[df['previous']<15], x="previous", hue="deposit", bins = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15], color = '#07CBF');
plt.xlabel("Nombres de contacts avec le client avant la campagne")
plt.ylabel('Nombre des clients')
plt.legend(title='Le client a-t-il souscrit a un depot a terme', loc='upper right', labels=['Oui', 'Non'], bbox_to_anchor= (1.9,1));

"""La proportion de personnes ayant effectué un deposit (vs ceux qui n'ont pas effectué de deposit) augmente à partir du 2ème contact durant la précédente campagne et au bout du 3ème contact la conversion est supérieure pour les personnes contactées une 3ème fois.

**CAMPAIGN / DEPOSIT**
"""

sns.histplot(data = df[df['campaign']<15], x="campaign", hue="deposit", bins = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15], color = '#07CBF');
plt.xlabel("Nombres de contacts effectués durant cette campagne par client?")
plt.ylabel('Nombre des clients')
plt.legend(title='Le client a-t-il souscrit a un depot a terme', loc='upper right', labels=['Oui', 'Non'], bbox_to_anchor= (1.9,1));

"""Durant la campagne actuelle, la proportion de souscription à un dépôt à terme reste environ constante pour 1, 2, 3, 4 appels (~10%) puis baisse."""

#@title
sns.catplot(x='previous',y='campaign', data=df, hue='deposit', alpha=0.7);

"""###4 - Variables socio-économiques

**EMPLOYEE VARIATION RATE / DEPOSIT**
"""

sns.violinplot(x="deposit", y = 'emp.var.rate', palette = colors, data=df)

"""Il semblerai que le taux d'emploi pourrait avoir une influence sur les souscriptions aux dépots. Une importante partie des personnes qui n'ont pas souscris à un dépot se retrouvent au dessus d'un taux de 0, et cela s'inverse pour les gens ayant souscrit à un depôt. A confirmer par un test de correlation.

**CONSUMER PRICE INDEX / DEPOSIT**
"""

sns.violinplot(x="deposit", y = 'cons.price.idx', palette = colors, data=df)

"""Le graphique ne semble pas indiquer de corrélation entre l'index du prix et la variable cible, mais à voir les tests.

**CONSUMER CONFIDENCE INDEX / DEPOSIT**
"""

sns.violinplot(x="deposit", y = 'cons.conf.idx', palette = colors, data=df)

"""Distribution anormale pour les personnes n'ayant pas souscrit pour un dépot. Difficile à observer une corrélation.

**TAUX EURIBOR 3 MOIS / DEPOSIT**
"""

sns.violinplot(x="deposit", y = 'euribor3m', data=df)

"""Distribution presque inversée entre les personnes ayant souscrit à un dépot et les personne n'ayant pas. Une corrélation est possible, à verifier avec les tests.

**NOMBRE D'EMPLOYÉES / DEPOSIT**
"""

sns.violinplot(x="deposit", y = 'nr.employed', palette = colors, data=df)

"""Distribution anormale pour les personnes ayant et n'ayant pas souscrit pour un dépot. Difficile à observer une corrélation pour l'instant.

## C - Tests de corrélation

Dans cette partie nous analyserons les corrélations entre les variables explicatives et la variable cible. 
Nous posons l'hypothése H0: 'La variable explicative et la variable cible sont indépendantes' pour l'ensemble des données afin d'éviter les répetions.

Création du df.corr, dataframe à utilisation unique sur le tests de corrélation.
"""

df_corr = df.drop(['educ', 'month_modif', 'age_cut', 'jobcat'], axis = 1)
df_corr.rename({'emp.var.rate': 'emp_var_rate', 'cons.price.idx': 'cons_price_idx', 'cons.conf.idx': 'cons_conf_idx',
                'nr.employed': 'nr_employed'}, axis = 1, inplace = True)

"""### 1 - Le Dataframe"""

cor = df.corr()

fig, ax = plt.subplots(figsize=(12,12))
sns.heatmap(cor, annot=True, ax=ax, cmap='coolwarm');

"""Première visualisation du niveau de corrélation sur l'ensemble de données du dataset en utilisant le Test de Pearson. Nous observons une très forte corrélation entre les variables du contexte socio-économique.

### 2 - Variables socio-démographiques

**AGE**
"""

result_age = statsmodels.formula.api.ols('age ~ deposit', data=df_corr).fit()
agean = statsmodels.api.stats.anova_lm(result_age)
agean

"""p-value (PR(>F)) > 5% -> on ne peut pas rejeter H0

**EDUCATION:**
"""

table2=pd.crosstab(df_corr['education'],df_corr['deposit'])


resultats_test=chi2_contingency(table2)
statistique = resultats_test[0]
p_valeur = resultats_test[1]
degre_liberte = resultats_test[2]

print(statistique, p_valeur,degre_liberte)

"""p-value > 5% -> on ne peut pas rejeter H0"""

def V_Cramer(table2, N):
    stat_chi2 = chi2_contingency(table2)[0]
    k = table2.shape[0]
    r = table2.shape[1]
    phi = max(0,(stat_chi2/N)-((k-1)*(r-1)/(N-1)))
    k_corr = k - (np.square(k-1)/(N-1))
    r_corr = r - (np.square(r-1)/(N-1))
    return np.sqrt(phi/min(k_corr - 1,r_corr - 1))

V_Cramer(table2, df.shape[0])

"""V-Cramer est très faible -> corrélation très faible entre 'education' et 'deposit'.

**MARITAL**
"""

table3=pd.crosstab(df_corr['marital'],df_corr['deposit'])


resultats_test=chi2_contingency(table3)
statistique = resultats_test[0]
p_valeur = resultats_test[1]
degre_liberte = resultats_test[2]

print(statistique, p_valeur,degre_liberte)

"""p-value > 5% -> on ne peut pas rejeter H0"""

def V_Cramer(table3, N):
    stat_chi2 = chi2_contingency(table3)[0]
    k = table3.shape[0]
    r = table3.shape[1]
    phi = max(0,(stat_chi2/N)-((k-1)*(r-1)/(N-1)))
    k_corr = k - (np.square(k-1)/(N-1))
    r_corr = r - (np.square(r-1)/(N-1))
    return np.sqrt(phi/min(k_corr - 1,r_corr - 1))

V_Cramer(table3, df.shape[0])

"""V de Cramer êxtremement faible -> corrélation très faible entre 'housing' et 'deposit', elle est donc négligeable.

**JOB**
"""

table4=pd.crosstab(df_corr['job'],df_corr['deposit'])


resultats_test=chi2_contingency(table4)
statistique = resultats_test[0]
p_valeur = resultats_test[1]
degre_liberte = resultats_test[2]

print(statistique, p_valeur,degre_liberte)

"""p-value > 5% -> on ne peut pas rejeter H0"""

def V_Cramer(table4, N):
    stat_chi2 = chi2_contingency(table4)[0]
    k = table4.shape[0]
    r = table4.shape[1]
    phi = max(0,(stat_chi2/N)-((k-1)*(r-1)/(N-1)))
    k_corr = k - (np.square(k-1)/(N-1))
    r_corr = r - (np.square(r-1)/(N-1))
    return np.sqrt(phi/min(k_corr - 1,r_corr - 1))

V_Cramer(table4, df.shape[0])

"""Le V de Cramer révele une corrélation êxtremement faible entre les variables housing et deposit, elle est donc négligeable.

###**3** - Variables financiéres

**LOAN**
"""

lode = pd.crosstab(df['loan'],df['deposit'])


resultats_test=chi2_contingency(lode)
statistique = resultats_test[0]
p_valeur = resultats_test[1]
degre_liberte = resultats_test[2]

print(statistique, p_valeur,degre_liberte)

"""p-value > 5% -> on ne peut pas rejeter H0"""

def V_Cramer(lode, N):
    stat_chi2 = chi2_contingency(lode)[0]
    k = lode.shape[0]
    r = lode.shape[1]
    phi = max(0,(stat_chi2/N)-((k-1)*(r-1)/(N-1)))
    k_corr = k - (np.square(k-1)/(N-1))
    r_corr = r - (np.square(r-1)/(N-1))
    return np.sqrt(phi/min(k_corr - 1,r_corr - 1))

V_Cramer(lode, df.shape[0])

"""V de Cramer confirme l'indépendance.

**HOUSING**
"""

hable=pd.crosstab(df['housing'],df['deposit'])

from scipy.stats import chi2_contingency
resultats_test=chi2_contingency(hable)
statistique = resultats_test[0]
p_valeur = resultats_test[1]
degre_liberte = resultats_test[2]

print(statistique, p_valeur,degre_liberte)

"""p-value > 5% -> on ne peut pas rejeter H0"""

def V_Cramer(hable, N):
    stat_chi2 = chi2_contingency(hable)[0]
    k = hable.shape[0]
    r = hable.shape[1]
    phi = max(0,(stat_chi2/N)-((k-1)*(r-1)/(N-1)))
    k_corr = k - (np.square(k-1)/(N-1))
    r_corr = r - (np.square(r-1)/(N-1))
    return np.sqrt(phi/min(k_corr - 1,r_corr - 1))

V_Cramer(hable, df.shape[0])

"""Le V de Cramer révele une corrélation êxtremement faible entre les variables housing et deposit, elle est donc négligeable.

**DEFAULT**
"""

dede=pd.crosstab(df['deposit'],df['default'])

resultats_test=chi2_contingency(dede)
statistique = resultats_test[0]
p_valeur = resultats_test[1]
degre_liberte = resultats_test[2]

print(statistique, p_valeur,degre_liberte)

"""p-value > 5% -> on ne peut pas rejeter H0"""

def V_Cramer(dede, N):
    stat_chi2 = chi2_contingency(dede)[0]
    k = dede.shape[0]
    r = dede.shape[1]
    phi = max(0,(stat_chi2/N)-((k-1)*(r-1)/(N-1)))
    k_corr = k - (np.square(k-1)/(N-1))
    r_corr = r - (np.square(r-1)/(N-1))
    return np.sqrt(phi/min(k_corr - 1,r_corr - 1))

V_Cramer(dede, df.shape[0])

"""Le V de Cramer révele une corrélation êxtremement faible entre les variables default et deposit, elle est donc négligeable.

### 4 - Variables concernant la campagne

**CONTACT**
"""

cece=pd.crosstab(df['contact'],df['default'])

resultats_test=chi2_contingency(cece)
statistique = resultats_test[0]
p_valeur = resultats_test[1]
degre_liberte = resultats_test[2]

print(statistique, p_valeur,degre_liberte)

"""p-value > 5% -> on ne peut pas rejeter H0"""

def V_Cramer(cece, N):
    stat_chi2 = chi2_contingency(cece)[0]
    k = cece.shape[0]
    r = cece.shape[1]
    phi = max(0,(stat_chi2/N)-((k-1)*(r-1)/(N-1)))
    k_corr = k - (np.square(k-1)/(N-1))
    r_corr = r - (np.square(r-1)/(N-1))
    return np.sqrt(phi/min(k_corr - 1,r_corr - 1))

V_Cramer(cece, df.shape[0])

"""Malgré la p-value, le V de Cramer révele une corrélation êxtremement faible entre les variables contact et deposit; elle est négligeable.

**MONTH**
"""

momo=pd.crosstab(df['month'],df['default'])

resultats_test=chi2_contingency(momo)
statistique = resultats_test[0]
p_valeur = resultats_test[1]
degre_liberte = resultats_test[2]

print(statistique, p_valeur,degre_liberte)

"""p-value > 5% -> on ne peut pas rejeter H0"""

def V_Cramer(momo, N):
    stat_chi2 = chi2_contingency(momo)[0]
    k = momo.shape[0]
    r = momo.shape[1]
    phi = max(0,(stat_chi2/N)-((k-1)*(r-1)/(N-1)))
    k_corr = k - (np.square(k-1)/(N-1))
    r_corr = r - (np.square(r-1)/(N-1))
    return np.sqrt(phi/min(k_corr - 1,r_corr - 1))

V_Cramer(momo, df.shape[0])

"""Malgré la p-value, le V de Cramer révele une corrélation êxtremement faible entre les variables month et deposit; elle est négligeable.

**DAY OF WEEK**
"""

dada=pd.crosstab(df['day_of_week'],df['default'])

resultats_test=chi2_contingency(dada)
statistique = resultats_test[0]
p_valeur = resultats_test[1]
degre_liberte = resultats_test[2]

print(statistique, p_valeur,degre_liberte)

"""p-value > 5% -> on ne peut pas rejeter H0"""

def V_Cramer(dada, N):
    stat_chi2 = chi2_contingency(dada)[0]
    k = dada.shape[0]
    r = dada.shape[1]
    phi = max(0,(stat_chi2/N)-((k-1)*(r-1)/(N-1)))
    k_corr = k - (np.square(k-1)/(N-1))
    r_corr = r - (np.square(r-1)/(N-1))
    return np.sqrt(phi/min(k_corr - 1,r_corr - 1))

V_Cramer(dada, df.shape[0])

"""Le V de Cramer révele une corrélation êxtremement faible entre les variables day_of_week et deposit; elle est négligeable.

**DURATION / CAMPAIGN / PDAYS / PREVIOUS**
"""

import statsmodels.api as sm
import statsmodels.formula.api as smf

anova_df = pd.DataFrame(columns=['variable'])

# ANOVA Test 
lst = ['duration','campaign','pdays','previous']

new_row=0
for item in lst:
    mod = smf.ols('{} ~ deposit'.format(item), data=df).fit()
    aov_table = sm.stats.anova_lm(mod, typ=1)
    anova_df=anova_df.append(aov_table)
    anova_df.iloc[[new_row-1], [0]] = item
    anova_df.iloc[[new_row-2], [0]] = item

anova_df.reset_index(inplace = True)
anova_df = anova_df.rename(columns={'index': '-'})
anova_df.head(100)

"""Pour les variables duration, pdays et previous la p-value (PR(>F)) est inférieure à 5% donc on rejette l'hypothèse selon laquelle elles n'influent pas sur deposit

Pour la variable campaign la p-value (PR(>F)) est supérieure à 5% donc on ne peut pas rejeter H0

**PREVIOUS OUTCOME**
"""

pepe=pd.crosstab(df['poutcome'],df['default'])

resultats_test=chi2_contingency(pepe)
statistique = resultats_test[0]
p_valeur = resultats_test[1]
degre_liberte = resultats_test[2]

print(statistique, p_valeur,degre_liberte)

"""p-value > 5% -> on ne peut pas rejeter H0"""

def V_Cramer(pepe, N):
    stat_chi2 = chi2_contingency(pepe)[0]
    k = pepe.shape[0]
    r = pepe.shape[1]
    phi = max(0,(stat_chi2/N)-((k-1)*(r-1)/(N-1)))
    k_corr = k - (np.square(k-1)/(N-1))
    r_corr = r - (np.square(r-1)/(N-1))
    return np.sqrt(phi/min(k_corr - 1,r_corr - 1))

V_Cramer(pepe, df.shape[0])

"""Malgré la p-value, le V de Cramer révele une corrélation êxtremement faible entre les variables poutcome et deposit; elle est négligeable.

### 5 - Variable concernant le contexte socio-économique

**EMP.VAR.RATE**
"""

import statsmodels.api as sm
from statsmodels.formula.api import ols

result_emp = statsmodels.formula.api.ols('emp_var_rate ~ deposit', data=df_corr).fit()
empe = statsmodels.api.stats.anova_lm(result_emp)
empe

"""la p-value (PR(>F)) est inférieure à 5% donc on rejette l'hypothèse selon laquelle emp.var.rate n'influe pas sur deposit

**CONS.PRICE.IDX**
"""

result_price = statsmodels.formula.api.ols('cons_price_idx ~ deposit', data=df_corr).fit()
prie = statsmodels.api.stats.anova_lm(result_price)
prie

"""la p-value (PR(>F)) > 5% -> on ne peut pas rejeter H0

**CONS.CONFIDENCE.IDX**
"""

result_conf = statsmodels.formula.api.ols('cons_conf_idx ~ deposit', data=df_corr).fit()
confe = statsmodels.api.stats.anova_lm(result_conf)
confe

"""la p-value (PR(>F)) > 5% -> on ne peut pas rejeter H0

**EURIBOR3M**
"""

result_eur = statsmodels.formula.api.ols('euribor3m ~ deposit', data=df_corr).fit()
euri = statsmodels.api.stats.anova_lm(result_eur)
euri

"""p-value (PR(>F)) < 5% donc on rejette l'hypothèse selon laquelle euribor3m n'influe pas sur deposit

**NR.EMPLOYEES**
"""

result_num = statsmodels.formula.api.ols('nr_employed ~ deposit', data=df_corr).fit()
num = statsmodels.api.stats.anova_lm(result_num)
num

"""p-value (PR(>F)) < 5% donc on rejette l'hypothèse selon laquelle nr.employed n'influe pas sur deposit

# **II - PREPROCESSING**
"""

df_ml = pd.DataFrame(data=df)


df_ml.drop(columns = ['age_cut','educ','month_modif','jobcat'], inplace = True)


df_ml.info()
df_ml.head()

"""Variables quantitatives"""

df_num = df_ml.select_dtypes(include=['int64', 'float64']).columns

scaler = preprocessing.StandardScaler().fit(df_ml[df_num])

df_ml[df_num] = pd.DataFrame(scaler.transform(df_ml[df_num]))

df_ml.head()

df_ml.info()

"""Variables qualitatives"""

df_cat = df_ml.select_dtypes(include=['object']).columns

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()

for feat in df_cat:
    df_ml[feat] = le.fit_transform(df_ml[feat].astype(str))

for col in df_cat:
    print(f"{col} has {df_ml[col].unique()} values\n")

df_ml.head()

df_ml.info()

target = df_ml['deposit']
feats = df_ml.drop('deposit',axis=1)

X_train, X_test, y_train, y_test = train_test_split(feats, target, test_size=0.2, random_state=12)

"""# **III - Machine Learning**

##A- ML SANS OverSlamping

Méthode de classification KNN (7min)
"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import cross_val_score

knn=KNeighborsClassifier()
params_knn={'n_neighbors': [k for k in range(1,10)], 'metric':['minkowski','manhattan','chebyshev']}

gridcv = GridSearchCV(estimator=knn, param_grid=params_knn, scoring='accuracy', cv=3)
gridcv.fit(X_train,y_train)

pd.DataFrame(gridcv.cv_results_)[['params', 'mean_test_score', 'std_test_score']]

gridcv.best_params_

knn_m = neighbors.KNeighborsClassifier(n_neighbors=9, metric='minkowski')
knn_m.fit(X_train, y_train)

y_pred = knn_m.predict(X_test)
pd.crosstab(y_test, y_pred, rownames=['Classe réelle'], colnames=['Classe prédite'])

print(knn_m.score(X_test, y_test))
print(classification_report(y_test, y_pred))

"""Suite à l'application du modèle KNN et de ses hyperparamètres, nous pouvons constater un score élevé de 0,90. Cependant, les métriques du modèle nous montre que la catégorie 1 de notre variable cible est difficilement détectable avec un F1 score de 0,46. Cela peut être dû à un déséquilibre important dans notre variable 'deposit'. Pour remédier à cela, nous allons effectuer un échantillonage avec la méthode de l'oversampling.

##B- ML AVEC OverSlamping
"""

print("Before OverSampling, counts of label '1': {}".format(sum(y_train == 1))) 
print("Before OverSampling, counts of label '0': {} \n".format(sum(y_train == 0))) 

#Importing SMOTE
from imblearn.over_sampling import SMOTE

#Oversampling the data
smote = SMOTE(random_state = 101)
X_train_over, y_train_over = smote.fit_resample(X_train, y_train)

print('After OverSampling, the shape of X_train: {}'.format(X_train_over.shape)) 
print('After OverSampling, the shape of y_train: {} \n'.format(y_train_over.shape)) 
  
print("After OverSampling, counts of label '1': {}".format(sum(y_train_over == 1))) 
print("After OverSampling, counts of label '0': {}".format(sum(y_train_over == 0)))

"""La méthode d'oversampling utilisée est le 'Smote'

###1- KNN (24min36s)
"""

knn=KNeighborsClassifier()
params_knn={'n_neighbors': [k for k in range(1,10)], 'metric':['minkowski','manhattan','chebyshev']}

grid_knn = GridSearchCV(estimator=knn, param_grid=params_knn, scoring='accuracy', cv=3)
grid_knn.fit(X_train_over,y_train_over)

grid_knn.best_params_

y_pred_knn = grid_knn.predict(X_test)
pd.crosstab(y_test, y_pred_knn, rownames=['Classe réelle'], colnames=['Classe prédite'])

print(grid_knn.score(X_test, y_test))
print(classification_report(y_test, y_pred_knn))

KNNCV=87
KNNCV_F1=49

"""###2- DecisionTree (17min33s)

"""

from sklearn.tree import DecisionTreeClassifier

dtree = DecisionTreeClassifier()
params_dtree = {'criterion' : ['gini', 'entropy'],
                'max_depth' : range(1,10),
                'min_samples_split' : range(1,10),
                'min_samples_leaf' : range(1,5)}

grid_dtree = GridSearchCV(estimator=dtree, param_grid=params_dtree, cv=10, verbose=1, n_jobs=-1 )
model_dtree = grid_dtree.fit(X_train_over,y_train_over)

model_dtree.best_params_

y_pred_dtree = model_dtree.predict(X_test)
pd.crosstab(y_test, y_pred_dtree, rownames=['Classe réelle'], colnames=['Classe prédite'])

print(model_dtree.score(X_test, y_test))
print(classification_report(y_test, y_pred_dtree))

model_dtree2 = DecisionTreeClassifier(criterion= 'gini',
 max_depth= 9,
 min_samples_leaf= 1,
 min_samples_split= 2)

model_dtree2.fit(X_train_over,y_train_over)

plt.figure(figsize=(20,15))
plot_tree(model_dtree2, feature_names = X_train_over.columns.tolist(), filled=True); #proportion=True

feats = {}
for feature, importance in zip(df_ml.columns, model_dtree.feature_importances_):
    feats[feature] = importance 
    
importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Importance'})
importances.sort_values(by='Importance', ascending=False).head(8)

from sklearn.tree import plot_tree
from sklearn.model_selection import GridSearchCV

DTREECV=87
DTREECV_F1=60

"""###3 - SVM (1h20)

"""

from sklearn import svm
from sklearn.model_selection import GridSearchCV, cross_val_score
from sklearn import model_selection
from sklearn.metrics import confusion_matrix, classification_report

svm = SVC()
param_svm = {"kernel": ["rbf"], "gamma": [1e-3, 1e-4], "C": [1, 10, 100, 1000]},


#param_svm2 = {'C': [0.1, 1, 10], 'gamma': [1, 0.1, 0.01], 'kernel': ['rbf']}

grid_svm = GridSearchCV(estimator=svm, param_grid=param_svm)

model_svm = grid_svm.fit(X_train_over, y_train_over)

grid_svm.best_params_

svm = SVC(C=1000, gamma=0.001, kernel= 'rbf')
model_svm = svm.fit(X_train_over, y_train_over)

feats = {}
for feature, importance in zip(df_ml.columns, svm.feature_importances_):
    feats[feature] = importance 
    
importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Importance'})
importances.sort_values(by='Importance', ascending=False).head(8)

y_pred_svm = grid_svm.predict(X_test)
pd.crosstab(y_test, y_pred_svm, rownames=['Classe réelle'], colnames=['Classe prédite'])

print(grid_svm.score(X_test, y_test))
print(classification_report(y_test, y_pred_svm))

SVCCV=91.0
SVCCV_F1=57

"""###4- Random Forest (14min45s)"""

from sklearn import ensemble
from sklearn import model_selection

RFC = ensemble.RandomForestClassifier(n_jobs=-1, random_state=321)

param_rfc = { 'n_estimators': [200, 700],
              'max_features': ['auto', 'sqrt', 'log2']}

grid_rfc = GridSearchCV(estimator=RFC, param_grid=param_rfc, cv= 5)
grid_rfc.fit(X_train_over, y_train_over)

grid_rfc.best_params_

y_pred_rfc = grid_rfc.predict(X_test)
pd.crosstab(y_test, y_pred_rfc, rownames=['Classe réelle'], colnames=['Classe prédite'])

print(grid_rfc.score(X_test, y_test))
print(classification_report(y_test, y_pred_rfc))

RFCCV=90
RFCCV_F1=63

"""Avec un score de 0,90 et un F1 score de 0,63 pour la prédiction de la classe '1', le random forest est l'une des méthodes de machine learning la plus adapté à notre dataset.

### 5- XGboost (1h04mins)
"""

from numpy import loadtxt
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

XGB = XGBClassifier(
    objective= 'binary:logistic',
    nthread=4,
    seed=42 )

param_xgb = {
    'max_depth': range (2, 10, 1),
    'n_estimators': range(60, 220, 40),
    'learning_rate': [0.1, 0.01, 0.05] }

grid_xgb = GridSearchCV(estimator=XGB, param_grid=param_xgb, scoring = 'roc_auc', 
                           verbose=True)
grid_xgb.fit(X_train_over, y_train_over)

grid_xgb.best_params_

y_pred_xgb = grid_xgb.predict(X_test)
pd.crosstab(y_test, y_pred_xgb, rownames=['Classe réelle'], colnames=['Classe prédite'])

print(grid_xgb.score(X_test, y_test))
print(classification_report(y_test, y_pred_xgb))

XGB=94
XGB_F1=63

"""### - **Evaluation des modèles**"""

#SVCCV=0
#KNNCV=0
LOGCV=0
#XGB=0

#DTREECV_F1=0
#KNNCV_F1=0
#SVCCV_F1=0
LOGCV_F1=0
#RFCCV_F1=0
#XGB_F1=0

models = pd.DataFrame({
                'Models': ['Decision Tree Classifier','K-Near Neighbors','Support Vector Machine','Random Forest Classifier', 'XGBoost',],
                'Accuracy':  [DTREECV,KNNCV,SVCCV,RFCCV,XGB],
                'F1_Score':  [DTREECV_F1,KNNCV_F1,SVCCV_F1,RFCCV_F1,XGB_F1],
                })

models.sort_values(by='Accuracy', ascending=False)

"""#**IV - Interprétation des modèles**"""



"""##A - SHAP

## - Installation
"""

# Commented out IPython magic to ensure Python compatibility.
!pip install shap

import shap

from IPython.display import display
# %matplotlib inline

"""### 1 - 1er modèle: XGB"""

#xgb = XGBClassifier(learning_rate =0.1, n_estimators=140, max_depth=4, min_child_weight=6, gamma=0.4, subsample=0.8, colsample_bytree=0.8, nthread=4, scale_pos_weight=1,seed=27)
#model_xgb = xgb.fit(X_train_over, y_train_over)

xgb = XGBClassifier(learning_rate =0.1, max_depth=9, n_estimators= 180)
model_xgb = xgb.fit(X_train_over, y_train_over)

expl_xgb = shap.TreeExplainer(model_xgb)
shap_xgb = expl_xgb.shap_values(X_train_over)

shap.summary_plot(shap_xgb, X_train_over, plot_type="bar")

shap.summary_plot(shap_xgb, X_train_over)

shap.initjs()
shap.force_plot(expl_xgb.expected_value, shap_xgb[1050,:], X_train_over.iloc[1050,:], link='logit')

shap.initjs()
shap.force_plot(expl_xgb.expected_value, shap_xgb[4000,:], X_train_over.iloc[4000,:], link='logit')

"""###2 - 2ème modèle: RFC"""

RFC = RandomForestClassifier(random_state=32)
model_rfc = RFC.fit(X_train_over, y_train_over)
#y_train_rfc = model_rfc.predict(X_train_over)
#y_test_rfc = model_rfc.predict(X_test)

expl_rfc = shap.TreeExplainer(model_rfc)
shap_rfc = expl_rfc.shap_values(X_test)

shap.summary_plot(shap_rfc, X_test, plot_type="bar")

shap.dependence_plot("duration", shap_rfc[1], X_test)

shap.dependence_plot("euribor3m", shap_rfc[0], X_test, interaction_index=None)

shap.dependence_plot("campaign", shap_rfc[0], X_test)

import numpy as np


#On ajoute les prédictions dans un dataset
X_output = X_train_over.copy()
X_output.loc[:,'predict'] = np.round(model_rfc.predict(X_output),2)

#On prend des observations au hasards
random_picks = np.arange(1,430,50)
S = X_output.iloc[random_picks]
S

#Affichage du force plot pour un individu n'ayant pas souscrit au dépot à terme
shap.initjs()
shap.force_plot(expl_rfc.expected_value[1], shap_rfc[1][251,:], X_train_over.iloc[251,:])

#Affichage du force plot pour un individu ayant souscrit au dépot à terme
shap.initjs()
shap.force_plot(expl_rfc.expected_value[0], shap_rfc[0][101,:], X_train_over.iloc[101
                                                                                ,:])

"""### 3 - 3ème modèle: Decision Tree"""

dtree = DecisionTreeClassifier(criterion = 'gini', max_depth = 9, min_samples_leaf = 1, min_samples_split = 2)
model_dtree = dtree.fit(X_train_over, y_train_over)
#y_train_dtree = model_dtree.predict(X_train_over)
#y_test_dtree = model_dtree.predict(X_test)

expl_dtree = shap.TreeExplainer(model_dtree)
shap_dtree = expl_dtree.shap_values(X_test)

shap.summary_plot(shap_dtree, X_train_over, plot_type="bar")

shap.initjs()
shap.force_plot(expl_dtree.expected_value[1], shap_dtree[1][850,:], X_train_over.iloc[850,:], link='logit')

shap.initjs()
shap.force_plot(expl_dtree.expected_value[1], shap_dtree[1][3008,:], X_train_over.iloc[3008,:], link='logit')

"""##B- LIME

## - Installation
"""

!pip install lime

import lime

from lime.lime_tabular import LimeTabularExplainer

"""###1 - 1er modèle : RFC"""

RFC.fit (X_train_over,y_train_over)
#y_train_rfc = RFC.predict(X_train_over)
#y_test_rfc = RFC.predict(X_test)

X_output=X_train_over.copy()
X_output.loc[:,'predict'] = np.round(RFC.predict(X_output),2)

random_picks=np.arange(40,460,50)
S=X_output.iloc[random_picks]
S

#Interprétabilité avec Lime pour un individu ayant souscrit au dépôt à terme
lime1 = LimeTabularExplainer(X_train_over.values, feature_names=X_train_over.columns,
                             discretize_continuous=False)

exp = lime1.explain_instance(X_train_over.values[340], RFC.predict_proba)
exp.show_in_notebook(show_table = True, show_all = True)

exp.as_pyplot_figure()
plt.tight_layout()

#Interprétabilité avec Lime pour un individu n'ayant pas souscrit au dépôt à terme
lime1 = LimeTabularExplainer(X_train_over.values, feature_names=X_train_over.columns,
                             discretize_continuous=False)

exp = lime1.explain_instance(X_train_over.values[390], RFC.predict_proba)

exp.show_in_notebook(show_table = True, show_all = True)

exp.as_pyplot_figure()
plt.tight_layout()

"""### 2 - 2ème modèle : Decision Tree"""

dtree = DecisionTreeClassifier(criterion = 'gini', max_depth = 9, min_samples_leaf = 1, min_samples_split = 2)
model_dtree = dtree.fit(X_train_over, y_train_over)

X_output=X_train_over.copy()
X_output.loc[:,'predict'] = np.round(model_dtree.predict(X_output),2)

random_picks=np.arange(40,460,50)
S=X_output.iloc[random_picks]
S

lime1 = LimeTabularExplainer(X_train_over.values, feature_names=X_train_over.columns,
                             discretize_continuous=False)

exp = lime1.explain_instance(X_train_over.values[340], model_dtree.predict_proba)
exp.show_in_notebook(show_table = True, show_all = True)

exp.as_pyplot_figure()
plt.tight_layout()

lime1 = LimeTabularExplainer(X_train_over.values, feature_names=X_train_over.columns,
                             discretize_continuous=False)

exp = lime1.explain_instance(X_train_over.values[390], model_dtree.predict_proba)

exp.show_in_notebook(show_table = True, show_all = True)

exp.as_pyplot_figure()
plt.tight_layout()

"""# LIBRAIRIES

"""

#from sklearn.tree import DecisionTreeClassifier
#from sklearn import decomposition, datasets
#from sklearn import tree
#from sklearn.pipeline import Pipeline
#from sklearn.model_selection import GridSearchCV
#from sklearn.preprocessing import StandardScaler
#from sklearn.metrics import accuracy_score
###
#from sklearn.metrics import accuracy_score
#from sklearn.metrics import roc_auc_score


import os
from sklearn.tree import DecisionTreeClassifier
from sklearn.tree import plot_tree
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import plot_confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.model_selection import RandomizedSearchCV
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier




import seaborn as sns
import matplotlib.pyplot as plt 
from sklearn import metrics
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix,r2_score
from sklearn import model_selection
from sklearn.ensemble import BaggingClassifier
import warnings
from imblearn.over_sampling import SMOTE
warnings.filterwarnings('ignore')
import tensorflow as tf
from tensorflow import keras 
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam 
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix


from sklearn import metrics
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, roc_curve, recall_score
from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold, RandomizedSearchCV, cross_val_score
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
import xgboost as xgb
from xgboost import XGBClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB



from sklearn.svm import SVC 
from sklearn.ensemble import RandomForestClassifier,VotingClassifier
from imblearn.under_sampling import RandomUnderSampler
from imblearn.over_sampling import RandomOverSampler, SMOTE
from collections import Counter
from pprint import pprint
from scipy import stats
from sklearn.preprocessing import StandardScaler
from xgboost import XGBClassifier

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt 
import seaborn as sns
from sklearn import metrics
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, roc_curve, recall_score
from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold, RandomizedSearchCV, cross_val_score
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
import xgboost as xgb
from xgboost import XGBClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC 
from sklearn.ensemble import RandomForestClassifier,VotingClassifier
from imblearn.under_sampling import RandomUnderSampler
from imblearn.over_sampling import RandomOverSampler, SMOTE
from collections import Counter
from pprint import pprint
from scipy import stats
from sklearn.preprocessing import StandardScaler

